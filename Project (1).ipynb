{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re, numpy as np, pandas as pd\n",
        "\n",
        "RAW = \"/content/UNSW_NB15_training-set.csv\"   # <-- your path\n",
        "OUT = \"/content/unsw_flows_labeled.csv\"\n",
        "\n",
        "def norm(s):  # normalize header\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
        "\n",
        "def find_one(df, *candidates):\n",
        "    cols = {norm(c): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if norm(cand) in cols:\n",
        "            return cols[norm(cand)]\n",
        "    return None\n",
        "\n",
        "def proto_to_str(x):\n",
        "    try:\n",
        "        x = int(x)\n",
        "        return {6: \"TCP\", 17: \"UDP\", 1: \"ICMP\"}.get(x, str(x))\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "# Common service→port guesses (extend as needed)\n",
        "SERVICE_PORT = {\n",
        "    \"http\":80, \"https\":443, \"dns\":53, \"ssh\":22, \"telnet\":23, \"smtp\":25, \"imap\":143, \"pop3\":110,\n",
        "    \"ftp\":21, \"ftp-data\":20, \"mysql\":3306, \"microsoft-ds\":445, \"smb\":445, \"rdp\":3389, \"ntp\":123,\n",
        "    \"snmp\":161, \"ldap\":389, \"kerberos\":88, \"dhcp\":67, \"dhcpv6\":546, \"irc\":6667, \"redis\":6379,\n",
        "    \"mongodb\":27017, \"postgresql\":5432, \"sql\":1433, \"smtp-ssl\":465, \"imap-ssl\":993, \"pop3-ssl\":995,\n",
        "    \"sip\":5060, \"rtsp\":554, \"ftp-control\":21, \"http-alt\":8080, \"ssl\":443\n",
        "}\n",
        "\n",
        "df_raw = pd.read_csv(RAW)\n",
        "print(\"Total cols:\", len(df_raw.columns))\n",
        "\n",
        "# Find core UNSW fields\n",
        "dur    = find_one(df_raw, \"dur\", \"duration\")\n",
        "spkts  = find_one(df_raw, \"spkts\", \"src_pkts\", \"s_pkts\")\n",
        "dpkts  = find_one(df_raw, \"dpkts\", \"dst_pkts\", \"d_pkts\")\n",
        "sbytes = find_one(df_raw, \"sbytes\", \"src_bytes\", \"s_bytes\")\n",
        "dbytes = find_one(df_raw, \"dbytes\", \"dst_bytes\", \"d_bytes\")\n",
        "sport  = find_one(df_raw, \"sport\", \"src_port\", \"s_port\")\n",
        "dport  = find_one(df_raw, \"dport\", \"dst_port\", \"d_port\")\n",
        "proto  = find_one(df_raw, \"proto\", \"protocol\")\n",
        "service= find_one(df_raw, \"service\")\n",
        "\n",
        "needed = [dur, spkts, dpkts, sbytes, dbytes, proto]\n",
        "if any(x is None for x in needed):\n",
        "    raise SystemExit(\"Missing core UNSW columns (dur/spkts/dpkts/sbytes/dbytes/proto). Share df_raw.columns if unsure.\")\n",
        "\n",
        "flows = pd.DataFrame()\n",
        "flows[\"duration\"] = df_raw[dur].astype(float).clip(lower=1e-6)\n",
        "flows[\"packets\"]  = df_raw[spkts].fillna(0).astype(float) + df_raw[dpkts].fillna(0).astype(float)\n",
        "flows[\"bytes\"]    = df_raw[sbytes].fillna(0).astype(float) + df_raw[dbytes].fillna(0).astype(float)\n",
        "flows[\"bytes_per_packet\"]   = (flows[\"bytes\"] / flows[\"packets\"].replace(0, np.nan)).fillna(0)\n",
        "flows[\"packets_per_second\"] = (flows[\"packets\"] / flows[\"duration\"]).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "\n",
        "# Fields not present in tabular UNSW → 0\n",
        "for c in [\"iat_mean\",\"iat_std\",\"tcp_syn\",\"tcp_ack\",\"tcp_rst\",\"tcp_fin\"]:\n",
        "    flows[c] = 0\n",
        "\n",
        "# Protocol as string\n",
        "flows[\"protocol\"] = df_raw[proto].apply(proto_to_str)\n",
        "\n",
        "# Ports: prefer real columns; otherwise infer dst_port from service, set src_port=0\n",
        "if sport is not None:\n",
        "    flows[\"src_port\"] = df_raw[sport].fillna(0).astype(int)\n",
        "else:\n",
        "    flows[\"src_port\"] = 0\n",
        "\n",
        "if dport is not None:\n",
        "    flows[\"dst_port\"] = df_raw[dport].fillna(0).astype(int)\n",
        "else:\n",
        "    if service is not None:\n",
        "        svc = df_raw[service].astype(str).str.lower().str.strip()\n",
        "        flows[\"dst_port\"] = svc.map(SERVICE_PORT).fillna(0).astype(int)\n",
        "        print(\"Info: inferred dst_port from 'service'. Unique services:\", sorted(svc.unique())[:25], \"...\")\n",
        "    else:\n",
        "        flows[\"dst_port\"] = 0\n",
        "        print(\"Warning: no dport/service — dst_port set to 0.\")\n",
        "\n",
        "# Labels\n",
        "attack_cat = find_one(df_raw, \"attack_cat\", \"attackcat\")\n",
        "label_num  = find_one(df_raw, \"label\")\n",
        "if attack_cat:\n",
        "    flows[\"label\"] = df_raw[attack_cat].fillna(\"Normal\").astype(str).str.strip().replace({\"\": \"Normal\"})\n",
        "elif label_num:\n",
        "    flows[\"label\"] = df_raw[label_num].apply(lambda x: \"Normal\" if str(x).strip() in {\"0\",\"normal\",\"benign\"} else \"Attack\")\n",
        "else:\n",
        "    raise SystemExit(\"Couldn’t find 'attack_cat' or 'label' for targets.\")\n",
        "\n",
        "print(flows.head(3))\n",
        "flows.to_csv(OUT, index=False)\n",
        "print(\" Wrote:\", OUT, \"rows:\", len(flows))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3QH4X_vrHhB",
        "outputId": "03fdc2d5-6d5f-4c5e-f24c-8facd7134335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total cols: 45\n",
            "Info: inferred dst_port from 'service'. Unique services: ['-', 'dhcp', 'dns', 'ftp', 'ftp-data', 'http', 'irc', 'pop3', 'radius', 'smtp', 'snmp', 'ssh', 'ssl'] ...\n",
            "   duration  packets   bytes  bytes_per_packet  packets_per_second  iat_mean  \\\n",
            "0  0.000011      2.0   496.0             248.0       181818.181818         0   \n",
            "1  0.000008      2.0  1762.0             881.0       250000.000000         0   \n",
            "2  0.000005      2.0  1068.0             534.0       400000.000000         0   \n",
            "\n",
            "   iat_std  tcp_syn  tcp_ack  tcp_rst  tcp_fin protocol  src_port  dst_port  \\\n",
            "0        0        0        0        0        0      udp         0         0   \n",
            "1        0        0        0        0        0      udp         0         0   \n",
            "2        0        0        0        0        0      udp         0         0   \n",
            "\n",
            "    label  \n",
            "0  Normal  \n",
            "1  Normal  \n",
            "2  Normal  \n",
            " Wrote: /content/unsw_flows_labeled.csv rows: 82332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python trainmodel.py \\\n",
        "  --train_csv /content/unsw_flows_labeled.csv \\\n",
        "  --out_dir artifacts --basename unsw --fast"
      ],
      "metadata": {
        "id": "cCQ4ZqL98tgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ed701-a402-4525-ab43-4007b3d6ccf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] FAST mode: fitting baseline RF…\n",
            "[OK] Saved preprocessor → /content/artifacts/unsw_preprocessor.pkl\n",
            "[OK] Saved classifier   → /content/artifacts/unsw_clf.pkl\n",
            "[OK] Saved feature importances → /content/artifacts/feature_importances.csv\n",
            "[OK] Saved metrics → /content/artifacts/metrics.json\n",
            "[OK] Saved confusion matrix → /content/artifacts/confusion_matrix.csv\n",
            "[INFO] Fitting IsolationForest on 29600 Normal training samples…\n",
            "[OK] Saved IsolationForest → /content/artifacts/unsw_iso.pkl\n",
            "[OK] Saved iso meta       → /content/artifacts/unsw_iso_meta.json\n",
            "[DONE] All artifacts & metrics saved in: /content/artifacts\n"
          ]
        }
      ]
    }
  ]
}